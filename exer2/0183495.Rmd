---
title: "0183495第二次作业"
output: html_document
---

第十题
```{r}
library(ISLR)
names(Weekly)
summary(Weekly)
```

a.由相关系数可看出year和volume相关性较强，没有其它模式
```{r}
pairs(Weekly)
cor(Weekly[,-9])
```
b.从每个变量的p值可看出，只有Lag2的p值最小，且小于0.5，是显著的预测变量，具有一定的统计学意义。
```{r}
attach(Weekly)
glm.fit=glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = Weekly, family = binomial)
summary(glm.fit)
```
c.整体正确预测比例为56.1%，在up中预测正确率为557/(557+48) = 92.1%，在down中预测正确率为54/(430+54) = 11.2%.
```{r}
glm.probs = predict(glm.fit, type = "response")
glm.probs[1:10]
contrasts(Direction)
glm.pred = rep("Down", length(glm.probs))
glm.pred[glm.probs > 0.5] = "Up"
table(glm.pred, Direction)
mean(glm.pred == Direction)
```
d.由此可看出正确率为62.5%
```{r}
train=(Year<2009)
Weekly.0910=Weekly[!train,]
Direction.0910 = Direction[!train]
glm.fit = glm(Direction ~ Lag2, data = Weekly, family = binomial, subset = train)
glm.probs = predict(glm.fit, Weekly.0910, type = "response")
glm.pred = rep("Down", length(glm.probs))
glm.pred[glm.probs > 0.5] = "Up"
table(glm.pred, Direction.0910)
mean(glm.pred == Direction.0910)
mean(glm.pred != Direction.0910)
```
e.
```{r}
library(MASS)
lda.fit = lda(Direction ~ Lag2, data = Weekly, subset = train)
lda.pred = predict(lda.fit, Weekly.0910)
table(lda.pred$class, Direction.0910)
mean(lda.pred$class == Direction.0910)
```

f.
```{r}
qda.fit = qda(Direction ~ Lag2, data = Weekly, subset = train)
qda.class = predict(qda.fit, Weekly.0910)$class
table(qda.class, Direction.0910)
mean(qda.class == Direction.0910)
```

g.
```{r}
library(class)
train.X = cbind(Lag2)[train,]
test.X = cbind(Lag2)[!train,]
train.Direction = Direction[train]
set.seed(6)
knn.pred = knn(as.matrix(train.X),as.matrix(test.X), train.Direction, k = 1)
table(knn.pred, Direction.0910)
mean(knn.pred == Direction.0910)
```
h.Logistic回归和LDA方法都有相似的测试错误率。


第十一题
a.
```{r}
library(ISLR)
summary(Auto)
attach(Auto)
mpg01 = rep(0, length(mpg))
mpg01[mpg > median(mpg)] = 1
Auto = data.frame(Auto, mpg01)
```
b.由相关系数表看出mpg ，cylinders，displacement，horsepower，weight变量对预测mpg01有影响，相关性较强。
```{r}
names(Auto)
cor(Auto[,-9])
pairs(Auto)
```
c.
```{r}
train = (year%%2 == 0)
test = !train
Auto.train = Auto[train, ]
Auto.test = Auto[test, ]
mpg01.test = mpg01[test]
```

d.测试错误率为12.6%
```{r}
lda.fit = lda(mpg01 ~ cylinders + weight + displacement + horsepower, data = Auto, subset = train)
lda.pred = predict(lda.fit, Auto.test)
mean(lda.pred$class != mpg01.test)
```
e.测试错误率为13.18%
```{r}
qda.fit = qda(mpg01 ~ cylinders + weight + displacement + horsepower, data = Auto, subset = train)
qda.pred = predict(qda.fit, Auto.test)
mean(qda.pred$class != mpg01.test)
```
f.测试错误率为12.08%
```{r}
glm.fit = glm(mpg01 ~ cylinders + weight + displacement + horsepower, data = Auto, 
    family = binomial, subset = train)
glm.probs = predict(glm.fit, Auto.test, type = "response")
glm.pred = rep(0, length(glm.probs))
glm.pred[glm.probs > 0.5] = 1
mean(glm.pred != mpg01.test)
```
g.由不同k值下的测试错误率可看出k=100时，错误率较小，为14.3%，说明k在100左右表现最好
```{r}
library(class)
train.X = cbind(cylinders, weight, displacement, horsepower)[train, ]
test.X = cbind(cylinders, weight, displacement, horsepower)[test, ]
train.mpg01 = mpg01[train]
set.seed(1)
# KNN(k=1)
knn.pred = knn(train.X, test.X, train.mpg01, k = 1)
mean(knn.pred != mpg01.test)
# KNN(k=50)
knn.pred = knn(train.X, test.X, train.mpg01, k = 10)
mean(knn.pred != mpg01.test)
# KNN(k=100)
knn.pred = knn(train.X, test.X, train.mpg01, k = 100)
mean(knn.pred != mpg01.test)
# KNN(k=120)
knn.pred = knn(train.X, test.X, train.mpg01, k = 120)
mean(knn.pred != mpg01.test)
```

